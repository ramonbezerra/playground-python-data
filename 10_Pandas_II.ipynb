{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulação de dados com Pandas II\n",
    "\n",
    "## Agregando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar o mesmo dataset da aula anterior de introdução ao Pandas, analisando também os preços dos produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('orders.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São funções de agregação básicas: contagem, valores máximo e mínimo, média, desvio padrão e variância dos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"count: \", df['price'].count())\n",
    "print(\"max: \", df['price'].max())\n",
    "print(\"min: \", df['price'].min())\n",
    "print(\"média: \", df['price'].mean())\n",
    "print(\"std: \", df['price'].std())\n",
    "print(\"var: \", df['price'].var())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São estatísticas básicas a mediana (2º quartil) e quartis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mediana: \", df['price'].median())\n",
    "print(\"quantile: \", df['price'].quantile(0))\n",
    "print(\"quantile: \", df['price'].quantile(0.25))\n",
    "print(\"quantile: \", df['price'].quantile(0.5))\n",
    "print(\"quantile: \", df['price'].quantile(0.75))\n",
    "print(\"quantile: \", df['price'].quantile(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = df.describe().round(2)\n",
    "describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para as colunas que não possuem valores numéricos, é possível estabelecer algumas verificações, como quantos e quais valores únicos cada uma delas possuem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shoe_material.unique())\n",
    "print(df.shoe_material.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para agrupar informações importantes, como, por exemplo, o preço mais alto por tipo de calçado, podemos utilizar a função `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_shoes = df.groupby('shoe_type').price.max()\n",
    "pricey_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar o resultado do agrupamento em um novo dataframe, basta acrescentar `reset_index()` no fim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_shoes = df.groupby('shoe_type').price.max().reset_index()\n",
    "pricey_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E assim podemos renomear as colunas, se for necessário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_shoes = pricey_shoes.rename(columns={'price': 'max_price'})\n",
    "pricey_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar o agrupamento com mais de uma coluna, basta passar uma lista como parâmetro da função `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_shoes_2 = df.groupby(['shoe_type', 'shoe_color']).price.max().reset_index().rename(columns={'price': 'max_price'})\n",
    "\n",
    "pricey_shoes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_shoes_3 = df.groupby(['shoe_type', 'shoe_color']).price.max().reset_index().rename(columns={'price': 'max_price'})\n",
    "\n",
    "pricey_shoes_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_counts = df.groupby(['shoe_type', 'shoe_color']).id.count().reset_index()\n",
    "\n",
    "shoe_counts = shoe_counts.rename(columns={'id':'count'})\n",
    "\n",
    "shoe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhor compreensão, analise outro exemplo: A Biblioteca Municipal tem várias filiais espalhadas pela cidade. Em cada uma delas são  coletados todos os dados de retirada de livros em um DataFrame chamado `checkouts`. \n",
    "\n",
    "O DataFrame contém as colunas `location`, `date` e `book_title`. Se quisermos comparar o número total de livros retirados em cada filial, qual código poderíamos usar?\n",
    "\n",
    "```\n",
    "checkouts.groupby(['location']).book_title.count().reset_index()\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo anterior, vimos que muitos dos dados se repetiram. Isso acontece porque fizemos o agrupamento por mais de uma coluna, o que pode ser resolvido estabelecendo um tabela pivô:\n",
    "\n",
    "```\n",
    "df.pivot(columns='ColumnToPivot',\n",
    "         index='ColumnToBeRows',\n",
    "         values='ColumnToBeValues')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_max_pivot = pricey_shoes_3.pivot(columns='shoe_color', index='shoe_type', values='max_price').reset_index()\n",
    "\n",
    "shoe_max_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_counts_pivot = shoe_counts.pivot(columns='shoe_color', index='shoe_type', values='count').reset_index()\n",
    "\n",
    "shoe_counts_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou aplicar duas ou mais métricas usando a função `agg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_shoes = df.groupby('shoe_type').price.agg(['max', 'min'])\n",
    "max_min_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível mesclar o cálculo de estatísticas com o agrupamento dos dados. Por exemplo, para calcular o percentil de 25% (1º quartil) do preço com base no agrupamento por cor do calçado, teremos os sapatos mais baratos assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cheap_shoes = df.groupby('shoe_color').price.apply(lambda x: np.percentile(x, 25)).reset_index()\n",
    "\n",
    "cheap_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['price', 'shoe_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_1 = pd.read_csv('tabela1.csv')\n",
    "tabela_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_2 = pd.read_csv('tabela2.csv')\n",
    "tabela_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_3 = pd.read_csv('tabela3.csv')\n",
    "tabela_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos como este método se comporta em dois cenários:\n",
    "\n",
    "### Cenário 1\n",
    "\n",
    "Vejamos como a método se comporta no caso de tabelas com as mesmas colunas. O método gera uma tabela com todas as combinações de colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tabela_1, tabela_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cenário 2\n",
    "\n",
    "Importaremos uma nova tabela chamada tabela_4, idêntica à tabela_3, porém com uma coluna a mais, a coluna ‘Animais’ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_4 = pd.read_csv('tabela4.csv')\n",
    "tabela_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tabela_1, tabela_4]).reset_index(drop=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as linhas que vieram da tabela_1 receberam ‘NaN’ na coluna ‘Animais’. Previsivelmente, afinal essa coluna só existe na tabela_4.\n",
    "\n",
    "Aqui, cada linha isolada não faz sentido. Mas o usuário pode filtrar a tabela para obter a informação que deseja.\n",
    "\n",
    "O código abaixo, por exemplo, nos retorna todos ‘Animais’ relacionados a ‘Nome’ igual a ‘João’, excluindo aqueles valores que aparecem como NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[(t['nome'] == 'João') & (t['animais'].notna())]['animais']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ajustar os índices, basta incluir o parâmetro `ignore_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tabela_1, tabela_4], ignore_index=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para concatenar horizontalmente, basta incluir o parâmetro `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([tabela_1, tabela_4], axis=1)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesclando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso queiramos a interseção exata entre as tabelas: `how = 'inner'`. Obtivemos a interseção entre as duas tabelas. Somente os valores na coluna “Nome” que existem em ambas tabelas aparecem no nosso resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = pd.merge(tabela_1, tabela_2, how='inner', on='nome')\n",
    "inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso queiramos todas as informações, de ambas tabelas, fazemos um merge `how = 'outer'`. Perceba que \"Pedro\" não possui dados para “Irmãos”. E “Marcelo” e “Thiago” não possuem dados para “Telefone” e “Carros”. Volte nas tabelas 1 e 2 veja que esse é exatamente o resultado esperado se quisermos todas as informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = pd.merge(tabela_1, tabela_2, how='outer', on='nome')\n",
    "outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um merge “left” ou “right” depende de qual tabela você deixa na direita ou esquerda. Para o seguinte cenário faremos um merge do tipo “left”. Mas o mesmo resultado pode ser obtido com um merge “right” trocando a posição das tabelas no método “merge”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.merge(tabela_1, tabela_2, how='left', on='nome')\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = pd.merge(tabela_2, tabela_1, how='right', on='nome')\n",
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cenários para merge left\n",
    "\n",
    "#### Cenário 1\n",
    "\n",
    "Suponhamos que para a sua tarefa você deva manter os dados da tabela_1 e ir acrescentando colunas conforme mais dados sobre ‘João’, ‘Pedro’ e ‘Caio’ apareçam. Em outras palavras, somente ‘Nomes’ que existam na tabela_1 serão trazidos da tabela_2. Neste exemplo deixaremos a tabela_1 à esquerda e faremos um merge ‘left’:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(tabela_1, tabela_2, how = 'left', on = 'nome')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cenário 2\n",
    "\n",
    "Neste cenário uniremos a tabela_1 à tabela_3. Perceba que a nova tabela, tabela_3, é igual a tabela_1 mas com valores novos para a coluna ‘Carros’.\n",
    "\n",
    "O que você acha que vai acontecer se tentarmos unir tabela_1 e tabela_3? Com qual valor para ‘Carros’ devemos ficar ao efetuarmos o seguinte merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(tabela_1, tabela_3, how = 'left', on = 'nome')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nossa chave para o merge sendo ‘nome’, todas outras colunas iguais entre as tabelas são separadas em _x e _y, onde:\n",
    "\n",
    "_x Corresponde aos valores que existiam na tabela da esquerda (tabela_1).\n",
    "_y Corresponde aos valores que existiam na tabela da direita (tabela_3).\n",
    "\n",
    "Esses sufixos podem ser alterados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.merge(tabela_1, tabela_3, how = 'left', on = 'nome').rename(columns = {'carros_x': 'carro antigo', 'carros_y': 'carro novo', 'telefone_x': 'telefone primário', 'telefone_y': 'telefone secundário'})\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
